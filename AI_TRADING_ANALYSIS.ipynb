{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b4f9d400",
      "metadata": {
        "id": "b4f9d400"
      },
      "source": [
        "Demonstration of MLFLOW."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5eb3c2b2",
      "metadata": {
        "id": "5eb3c2b2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install smartapi-python pandas numpy matplotlib pyotp logzero websocket-client pycryptodome\n",
        "!pip install xgboost matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVLBu-saqZ7B",
        "outputId": "e2fb9f50-1d05-4f3e-eccd-ecce231b3bfb"
      },
      "id": "CVLBu-saqZ7B",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting smartapi-python\n",
            "  Downloading smartapi_python-1.5.5-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting pyotp\n",
            "  Downloading pyotp-2.9.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting logzero\n",
            "  Downloading logzero-1.7.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.11/dist-packages (from smartapi-python) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from smartapi-python) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from smartapi-python) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->smartapi-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->smartapi-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->smartapi-python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->smartapi-python) (2025.1.31)\n",
            "Downloading smartapi_python-1.5.5-py3-none-any.whl (28 kB)\n",
            "Downloading pyotp-2.9.0-py3-none-any.whl (13 kB)\n",
            "Downloading logzero-1.7.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: logzero, pyotp, pycryptodome, smartapi-python\n",
            "Successfully installed logzero-1.7.0 pycryptodome-3.21.0 pyotp-2.9.0 smartapi-python-1.5.5\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7yuD5hfq9Ne",
        "outputId": "ecfdbce1-4dff-4929-bd95-3a6aac2523a3"
      },
      "id": "n7yuD5hfq9Ne",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.20.1-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting mlflow-skinny==2.20.1 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.20.1-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<19,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (17.0.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.37)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.20.1->mlflow)\n",
            "  Downloading databricks_sdk-0.43.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (4.25.6)\n",
            "Requirement already satisfied: pydantic<3,>=1.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (2.10.6)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.1->mlflow) (4.12.2)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.1->mlflow) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.20.1->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.20.1->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.1->mlflow) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.1->mlflow) (75.1.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.20.1->mlflow) (0.37b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.0->mlflow-skinny==2.20.1->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.0->mlflow-skinny==2.20.1->mlflow) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.1->mlflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.1->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.1->mlflow) (2025.1.31)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.1->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.20.1->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.1->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.1->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.1->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.20.1-py3-none-any.whl (28.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m28.3/28.3 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.20.1-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.43.0-py3-none-any.whl (647 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m647.4/647.4 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, gunicorn, graphql-core, graphql-relay, docker, alembic, graphene, databricks-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed Mako-1.3.9 alembic-1.14.1 databricks-sdk-0.43.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.20.1 mlflow-skinny-2.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import pyotp\n",
        "from logzero import logger\n",
        "from SmartApi.smartConnect import SmartConnect\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tabulate import tabulate\n",
        "\n",
        "# =======================\n",
        "# ðŸ”¹ USER CONFIGURATION\n",
        "# =======================\n",
        "API_KEY = \"uMU5cqo6\"\n",
        "CLIENT_CODE = \"P62342768\"\n",
        "PASSWORD = \"2611\"\n",
        "TOTP_SECRET = \"PHWQUE25HTYKZ4WMWCGNOB5RQU\"\n",
        "EXCHANGE = \"NSE\"\n",
        "INTERVAL = \"FIVE_MINUTE\"\n",
        "\n",
        "# Top 5 stocks for analysis\n",
        "STOCKS_TO_ANALYZE = [\"11256\", \"11626\", \"11253\", \"11580\", \"24969\"]\n",
        "\n",
        "# =======================\n",
        "# ðŸ”¹ HELPER FUNCTIONS\n",
        "# =======================\n",
        "def login_smart_api():\n",
        "    \"\"\"Login to the Smart API.\"\"\"\n",
        "    try:\n",
        "        obj = SmartConnect(api_key=API_KEY)\n",
        "        totp = pyotp.TOTP(TOTP_SECRET).now()\n",
        "        obj.generateSession(CLIENT_CODE, PASSWORD, totp)\n",
        "        return obj\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Login Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def fetch_historical_data(api_obj, stock_token, from_date, to_date):\n",
        "    \"\"\"Fetch historical data for a stock.\"\"\"\n",
        "    try:\n",
        "        params = {\n",
        "            \"exchange\": EXCHANGE,\n",
        "            \"symboltoken\": stock_token,\n",
        "            \"interval\": INTERVAL,\n",
        "            \"fromdate\": from_date,\n",
        "            \"todate\": to_date,\n",
        "        }\n",
        "        data = api_obj.getCandleData(params)\n",
        "        df = pd.DataFrame(data['data'], columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Data Fetch Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def validate_prediction(validation_df, signal, target_price, stop_loss):\n",
        "    \"\"\"Validate if target or stop loss was hit.\"\"\"\n",
        "    try:\n",
        "        if signal == \"BUY\":\n",
        "            target_hit = validation_df[validation_df['high'] >= target_price]\n",
        "            stop_hit = validation_df[validation_df['low'] <= stop_loss]\n",
        "        else:\n",
        "            target_hit = validation_df[validation_df['low'] <= target_price]\n",
        "            stop_hit = validation_df[validation_df['high'] >= stop_loss]\n",
        "\n",
        "        if not target_hit.empty:\n",
        "            return \"Target Hit\", target_hit.iloc[0]['timestamp']\n",
        "        elif not stop_hit.empty:\n",
        "            return \"Stop Loss Hit\", stop_hit.iloc[0]['timestamp']\n",
        "        else:\n",
        "            return \"No Outcome\", None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Validation Error: {e}\")\n",
        "        return \"Error\", None\n",
        "\n",
        "# =======================\n",
        "# ðŸ”¹ MODEL DEFINITIONS\n",
        "# =======================\n",
        "def model1_logistic_rsi(train_df):\n",
        "    \"\"\"Logistic Regression with RSI.\"\"\"\n",
        "    try:\n",
        "        # Feature Engineering\n",
        "        delta = train_df['close'].diff()\n",
        "        gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
        "        train_df['RSI'] = 100 - (100 / (1 + (gain / loss)))\n",
        "        train_df.dropna(inplace=True)\n",
        "\n",
        "        if len(train_df) < 15:\n",
        "            return None  # Insufficient data\n",
        "\n",
        "        # Prepare data\n",
        "        X = train_df[['RSI']][:-1]\n",
        "        y = np.where(train_df['close'].shift(-1) > train_df['close'], 1, 0)[:-1]\n",
        "\n",
        "        # Train model\n",
        "        model = LogisticRegression()\n",
        "        model.fit(X, y)\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Model 1 Training Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def model2_xgb_basic(train_df):\n",
        "    \"\"\"XGBoost with OHLCV features.\"\"\"\n",
        "    try:\n",
        "        train_df['target'] = (train_df['close'].pct_change().shift(-1) > 0).astype(int)\n",
        "        train_df.dropna(inplace=True)\n",
        "\n",
        "        if len(train_df) < 10:\n",
        "            return None\n",
        "\n",
        "        X = train_df[['open', 'high', 'low', 'close', 'volume']][:-1]\n",
        "        y = train_df['target'][:-1]\n",
        "\n",
        "        model = XGBClassifier()\n",
        "        model.fit(X, y)\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Model 2 Training Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def model3_xgb_advanced(train_df):\n",
        "    \"\"\"XGBoost with advanced features.\"\"\"\n",
        "    try:\n",
        "        # Feature Engineering\n",
        "        train_df['SMA_5'] = train_df['close'].rolling(5).mean()\n",
        "        train_df['SMA_10'] = train_df['close'].rolling(10).mean()\n",
        "        train_df['momentum'] = train_df['close'] - train_df['close'].shift(5)\n",
        "        train_df['breakout'] = (train_df['close'] > train_df['high'].rolling(10).max().shift(1)).astype(int)\n",
        "        train_df.dropna(inplace=True)\n",
        "\n",
        "        if len(train_df) < 15:\n",
        "            return None\n",
        "\n",
        "        X = train_df[['momentum', 'breakout', 'SMA_5', 'SMA_10']][:-1]\n",
        "        y = np.where(train_df['close'].shift(-1) > train_df['close'], 1, 0)[:-1]\n",
        "\n",
        "        model = XGBClassifier()\n",
        "        model.fit(X, y)\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Model 3 Training Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def model4_random_forest(train_df):\n",
        "    \"\"\"Random Forest with multiple indicators.\"\"\"\n",
        "    try:\n",
        "        train_df['SMA_5'] = train_df['close'].rolling(5).mean()\n",
        "        train_df['SMA_10'] = train_df['close'].rolling(10).mean()\n",
        "        train_df['momentum'] = train_df['close'] - train_df['close'].shift(5)\n",
        "        train_df.dropna(inplace=True)\n",
        "\n",
        "        if len(train_df) < 15:\n",
        "            return None\n",
        "\n",
        "        X = train_df[['SMA_5', 'SMA_10', 'momentum']][:-1]\n",
        "        y = np.where(train_df['close'].shift(-1) > train_df['close'], 1, 0)[:-1]\n",
        "\n",
        "        model = RandomForestClassifier()\n",
        "        model.fit(X, y)\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Model 4 Training Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def model5_svm(train_df):\n",
        "    \"\"\"SVM with technical patterns.\"\"\"\n",
        "    try:\n",
        "        train_df['SMA_5'] = train_df['close'].rolling(5).mean()\n",
        "        train_df['SMA_10'] = train_df['close'].rolling(10).mean()\n",
        "        train_df['momentum'] = train_df['close'] - train_df['close'].shift(5)\n",
        "        train_df.dropna(inplace=True)\n",
        "\n",
        "        if len(train_df) < 15:\n",
        "            return None\n",
        "\n",
        "        X = train_df[['SMA_5', 'SMA_10', 'momentum']][:-1]\n",
        "        y = np.where(train_df['close'].shift(-1) > train_df['close'], 1, 0)[:-1]\n",
        "\n",
        "        model = SVC()\n",
        "        model.fit(X, y)\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Model 5 Training Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# =======================\n",
        "# ðŸ”¹ PREDICTION FUNCTIONS\n",
        "# =======================\n",
        "def predict_model1(model, train_df):\n",
        "    \"\"\"Predict using Logistic Regression (RSI).\"\"\"\n",
        "    try:\n",
        "        latest_data = train_df[['RSI']].iloc[-1:]\n",
        "        prediction = model.predict(latest_data)[0]\n",
        "        close_price = train_df['close'].iloc[-1]\n",
        "\n",
        "        if prediction == 1:\n",
        "            return \"BUY\", round(close_price * 1.01, 2), round(close_price * 0.98, 2)\n",
        "        else:\n",
        "            return \"SELL\", round(close_price * 0.99, 2), round(close_price * 1.02, 2)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Model1 Prediction Error: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "def predict_model2(model, train_df):\n",
        "    \"\"\"Predict using XGBoost (Basic).\"\"\"\n",
        "    try:\n",
        "        latest_data = train_df[['open', 'high', 'low', 'close', 'volume']].iloc[-1:]\n",
        "        prediction = model.predict(latest_data)[0]\n",
        "        close_price = latest_data['close'].values[0]\n",
        "\n",
        "        if prediction == 1:\n",
        "            return \"BUY\", round(close_price * 1.015, 2), round(close_price * 0.985, 2)\n",
        "        else:\n",
        "            return \"SELL\", round(close_price * 0.985, 2), round(close_price * 1.015, 2)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Model2 Prediction Error: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# =======================\n",
        "# ðŸ”¹ MAIN EXECUTION\n",
        "# =======================\n",
        "if __name__ == \"__main__\":\n",
        "    api_obj = login_smart_api()\n",
        "    if not api_obj:\n",
        "        exit(\"Failed to login to API\")\n",
        "\n",
        "    # Define models to compare\n",
        "    MODELS = [\n",
        "        {\n",
        "            'name': 'Logistic Regression (RSI)',\n",
        "            'train': model1_logistic_rsi,\n",
        "            'predict': predict_model1\n",
        "        },\n",
        "        {\n",
        "            'name': 'XGBoost (Basic)',\n",
        "            'train': model2_xgb_basic,\n",
        "            'predict': predict_model2\n",
        "        },\n",
        "        {\n",
        "            'name': 'XGBoost (Advanced)',\n",
        "            'train': model3_xgb_advanced,\n",
        "            'predict': predict_model2\n",
        "        },\n",
        "        {\n",
        "            'name': 'Random Forest',\n",
        "            'train': model4_random_forest,\n",
        "            'predict': predict_model2\n",
        "        },\n",
        "        {\n",
        "            'name': 'SVM',\n",
        "            'train': model5_svm,\n",
        "            'predict': predict_model2\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for stock in STOCKS_TO_ANALYZE:\n",
        "        logger.info(f\"Analyzing {stock}...\")\n",
        "\n",
        "        # Fetch training and validation data\n",
        "        train_df = fetch_historical_data(api_obj, stock, \"2025-02-06 09:30\", \"2025-02-06 12:30\")\n",
        "        valid_df = fetch_historical_data(api_obj, stock, \"2025-02-06 12:30\", \"2025-02-06 15:15\")\n",
        "\n",
        "        if train_df is None or valid_df is None:\n",
        "            continue\n",
        "\n",
        "        for model in MODELS:\n",
        "            try:\n",
        "                # Train model\n",
        "                trained_model = model['train'](train_df)\n",
        "                if not trained_model:\n",
        "                    continue\n",
        "\n",
        "                # Predict and validate\n",
        "                signal, target, sl = model['predict'](trained_model, train_df)\n",
        "                result, event_time = validate_prediction(valid_df, signal, target, sl)\n",
        "\n",
        "                # Store results\n",
        "                results.append({\n",
        "                    'Stock': stock,\n",
        "                    'Model': model['name'],\n",
        "                    'Signal': signal,\n",
        "                    'Target': target,\n",
        "                    'Stop Loss': sl,\n",
        "                    'Result': result,\n",
        "                    'Event Time': event_time\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"{model['name']} failed: {str(e)}\")\n",
        "\n",
        "    # Generate report\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(tabulate(results_df, headers='keys', tablefmt='pretty', showindex=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWVW8fh7qlms",
        "outputId": "f9d09c85-15a3-4b47-c7d1-5c63904e2932"
      },
      "id": "PWVW8fh7qlms",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 250210 16:26:09 smartConnect:124] in pool\n",
            "[I 250210 16:26:11 <ipython-input-4-dd20a62916e9>:264] Analyzing 11256...\n",
            "[E 250210 16:26:13 <ipython-input-4-dd20a62916e9>:221] Model2 Prediction Error: feature_names mismatch: ['momentum', 'breakout', 'SMA_5', 'SMA_10'] ['open', 'high', 'low', 'close', 'volume']\n",
            "    expected momentum, SMA_5, SMA_10, breakout in input data\n",
            "    training data did not have the following fields: high, open, low, volume, close\n",
            "[I 250210 16:26:13 <ipython-input-4-dd20a62916e9>:264] Analyzing 11626...\n",
            "[E 250210 16:26:14 <ipython-input-4-dd20a62916e9>:221] Model2 Prediction Error: feature_names mismatch: ['momentum', 'breakout', 'SMA_5', 'SMA_10'] ['open', 'high', 'low', 'close', 'volume']\n",
            "    expected momentum, SMA_5, SMA_10, breakout in input data\n",
            "    training data did not have the following fields: high, open, low, volume, close\n",
            "[I 250210 16:26:14 <ipython-input-4-dd20a62916e9>:264] Analyzing 11253...\n",
            "[E 250210 16:26:16 <ipython-input-4-dd20a62916e9>:221] Model2 Prediction Error: feature_names mismatch: ['momentum', 'breakout', 'SMA_5', 'SMA_10'] ['open', 'high', 'low', 'close', 'volume']\n",
            "    expected momentum, SMA_5, SMA_10, breakout in input data\n",
            "    training data did not have the following fields: high, open, low, volume, close\n",
            "[I 250210 16:26:16 <ipython-input-4-dd20a62916e9>:264] Analyzing 11580...\n",
            "[I 250210 16:26:18 <ipython-input-4-dd20a62916e9>:264] Analyzing 24969...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------------------------+--------+--------+-----------+---------------+---------------------------+\n",
            "| Stock |           Model           | Signal | Target | Stop Loss |    Result     |        Event Time         |\n",
            "+-------+---------------------------+--------+--------+-----------+---------------+---------------------------+\n",
            "| 11256 | Logistic Regression (RSI) |  SELL  | 143.54 |  147.89   | Stop Loss Hit | 2025-02-06 14:00:00+05:30 |\n",
            "| 11256 |      XGBoost (Basic)      |  SELL  | 142.82 |  147.16   | Stop Loss Hit | 2025-02-06 14:00:00+05:30 |\n",
            "| 11256 |    XGBoost (Advanced)     |        |  nan   |    nan    |  No Outcome   |            NaT            |\n",
            "| 11626 | Logistic Regression (RSI) |  SELL  | 571.72 |  589.05   |  No Outcome   |            NaT            |\n",
            "| 11626 |      XGBoost (Basic)      |  SELL  | 568.84 |  586.16   |  No Outcome   |            NaT            |\n",
            "| 11626 |    XGBoost (Advanced)     |        |  nan   |    nan    |  No Outcome   |            NaT            |\n",
            "| 11253 | Logistic Regression (RSI) |  SELL  | 129.07 |  132.98   |  No Outcome   |            NaT            |\n",
            "| 11253 |      XGBoost (Basic)      |  SELL  | 128.41 |  132.33   |  No Outcome   |            NaT            |\n",
            "| 11253 |    XGBoost (Advanced)     |        |  nan   |    nan    |  No Outcome   |            NaT            |\n",
            "| 11580 | Logistic Regression (RSI) |  SELL  | 864.57 |  890.77   |  Target Hit   | 2025-02-06 12:40:00+05:30 |\n",
            "| 11580 |      XGBoost (Basic)      |  BUY   | 886.4  |   860.2   | Stop Loss Hit | 2025-02-06 13:00:00+05:30 |\n",
            "| 24969 | Logistic Regression (RSI) |  SELL  | 319.27 |  328.95   |  Target Hit   | 2025-02-06 13:15:00+05:30 |\n",
            "| 24969 |      XGBoost (Basic)      |  BUY   | 327.34 |  317.66   |  Target Hit   | 2025-02-06 14:30:00+05:30 |\n",
            "+-------+---------------------------+--------+--------+-----------+---------------+---------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0878fc4c",
      "metadata": {
        "id": "0878fc4c",
        "outputId": "4057b5b0-65ed-433c-b184-8bbe5054e295",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([900, 100]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Ideally you will not require following 4 lines if you have started fresh and do not have any previous dagshub credentials on your computer\n",
        "import os\n",
        "os.environ['MLFLOW_TRACKING_USERNAME'] = 'DID-85' # 'learnpythonlanguage'\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = 'Didhit@1234' #\n",
        "os.environ['MLFLOW_TRACKING_URI'] = 'https://dagshub.com/DID-85/MlFlow_Demo_didhit_patel.mlflow' # https://dagshub.com/learnpythonlanguage/mlflow_dagshub_demo.mlflow\n",
        "\n",
        "\n",
        "\n",
        "# Your existing models definition:\n",
        "MODELS = [\n",
        "    {\n",
        "        'name': 'Logistic Regression (RSI)',\n",
        "        'train': model1_logistic_rsi,  # Function that trains and returns a trained Logistic Regression model using RSI features\n",
        "        'predict': predict_model1      # Function that predicts given the trained model and test data\n",
        "    },\n",
        "    {\n",
        "        'name': 'XGBoost (Basic)',\n",
        "        'train': model2_xgb_basic,\n",
        "        'predict': predict_model2\n",
        "    },\n",
        "    {\n",
        "        'name': 'XGBoost (Advanced)',\n",
        "        'train': model3_xgb_advanced,\n",
        "        'predict': predict_model2\n",
        "    },\n",
        "    {\n",
        "        'name': 'Random Forest',\n",
        "        'train': model4_random_forest,\n",
        "        'predict': predict_model2\n",
        "    },\n",
        "    {\n",
        "        'name': 'SVM',\n",
        "        'train': model5_svm,\n",
        "        'predict': predict_model2\n",
        "    }\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "# Loop through each model, train, evaluate, and log with MLflow\n",
        "for model_info in MODELS:\n",
        "    model_name = model_info['name']\n",
        "    train_func = model_info['train']\n",
        "    predict_func = model_info['predict']\n",
        "\n",
        "    with mlflow.start_run(run_name=model_name):\n",
        "        # Train the model (assumes the train function returns a trained model instance)\n",
        "        trained_model = train_func()\n",
        "\n",
        "        # Predict on test data using your predict function.\n",
        "        # It is assumed that your predict function signature accepts (trained_model, X_test).\n",
        "        y_pred = predict_func(trained_model, X_test)\n",
        "\n",
        "        # Calculate the accuracy (or any other metric you prefer)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Log the metric\n",
        "        mlflow.log_metric('accuracy', accuracy)\n",
        "\n",
        "        # Log the model. If your trained_model is a scikit-learn model, this works directly.\n",
        "        mlflow.sklearn.log_model(trained_model, model_name)\n",
        "\n",
        "        # Optionally, log additional parameters if available:\n",
        "        # For example, if your train function uses internal parameters, you could log them here.\n",
        "        # mlflow.log_param('some_parameter', value)\n",
        "\n",
        "        results.append({'model': model_name, 'accuracy': accuracy})\n",
        "\n",
        "        print(f\"Logged {model_name} with accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u44Ub38_UmUQ"
      },
      "id": "u44Ub38_UmUQ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}